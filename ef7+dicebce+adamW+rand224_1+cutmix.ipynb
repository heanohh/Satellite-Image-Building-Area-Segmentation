{"cells":[{"cell_type":"markdown","metadata":{"id":"z-yeM27xLt8K"},"source":["## Import"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QP2H26BdkZ-2","executionInfo":{"status":"ok","timestamp":1690481836911,"user_tz":-540,"elapsed":5012,"user":{"displayName":"박지원","userId":"06387002305792707333"}},"outputId":"dd653143-51f0-4db5-9c81-487ec3a9d491"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":1,"metadata":{"id":"b_-olK3xIiyc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690481524393,"user_tz":-540,"elapsed":397951,"user":{"displayName":"박지원","userId":"06387002305792707333"}},"outputId":"6f094bbb-0615-4348-ccf2-4baeabaefb88"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/data_2023\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","#압축파일 풀 곳\n","!mkdir data_2023\n","\n","#데이터있는 주소\n","!unzip -qq drive/MyDrive/open.zip -d./data_2023\n","\n","%cd data_2023"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"shS2gYPtJB7n","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690481540011,"user_tz":-540,"elapsed":15627,"user":{"displayName":"박지원","userId":"06387002305792707333"}},"outputId":"6bba9201-f1a3-4028-faf3-f6447014a73b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting segmentation-models-pytorch\n","  Downloading segmentation_models_pytorch-0.3.3-py3-none-any.whl (106 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (0.15.2+cu118)\n","Collecting pretrainedmodels==0.7.4 (from segmentation-models-pytorch)\n","  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting efficientnet-pytorch==0.7.1 (from segmentation-models-pytorch)\n","  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting timm==0.9.2 (from segmentation-models-pytorch)\n","  Downloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (4.65.0)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (9.4.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.0.1+cu118)\n","Collecting munch (from pretrainedmodels==0.7.4->segmentation-models-pytorch)\n","  Downloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation-models-pytorch) (6.0.1)\n","Collecting huggingface-hub (from timm==0.9.2->segmentation-models-pytorch)\n","  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors (from timm==0.9.2->segmentation-models-pytorch)\n","  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.22.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (2.27.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (4.7.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (16.0.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (2023.6.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (23.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2023.7.22)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (3.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.3.0)\n","Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n","  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16428 sha256=a4e2517290d71c05c9520790d3fea197da5beec39360beb2d032b9b91fe2559d\n","  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n","  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60944 sha256=27dc4082e8b68acf84a890b544c72c810ede4db47abf636d4e9de3617b6da193\n","  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\n","Successfully built efficientnet-pytorch pretrainedmodels\n","Installing collected packages: safetensors, munch, huggingface-hub, timm, pretrainedmodels, efficientnet-pytorch, segmentation-models-pytorch\n","Successfully installed efficientnet-pytorch-0.7.1 huggingface-hub-0.16.4 munch-4.0.0 pretrainedmodels-0.7.4 safetensors-0.3.1 segmentation-models-pytorch-0.3.3 timm-0.9.2\n","Collecting adamp\n","  Downloading adamp-0.3.0.tar.gz (5.1 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: adamp\n","  Building wheel for adamp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for adamp: filename=adamp-0.3.0-py3-none-any.whl size=5979 sha256=fc1d0a964f29ae7bc831df1cd84b931fc983f961c40b7b930b8bb5bc33541a58\n","  Stored in directory: /root/.cache/pip/wheels/c7/ad/0f/b41b1c45b18c66e5eef5d2254415af8055c7e2b0934145157d\n","Successfully built adamp\n","Installing collected packages: adamp\n","Successfully installed adamp-0.3.0\n"]}],"source":["%pip install segmentation-models-pytorch\n","%pip install adamp"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12704,"status":"ok","timestamp":1690481552705,"user":{"displayName":"박지원","userId":"06387002305792707333"},"user_tz":-540},"id":"VolGYa0kJKqY","outputId":"d7fd1740-6b77-4cf1-c243-8ec93d17f9d7"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}],"source":["import os\n","import cv2\n","import pandas as pd\n","import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","\n","from tqdm import tqdm\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","from typing import List, Union\n","from joblib import Parallel, delayed\n","\n","import segmentation_models_pytorch as smp\n","import argparse\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"]},{"cell_type":"markdown","metadata":{"id":"3KnPjwNmLwfR"},"source":["## Utils"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"88cEQaQyLhJZ","executionInfo":{"status":"ok","timestamp":1690481552706,"user_tz":-540,"elapsed":36,"user":{"displayName":"박지원","userId":"06387002305792707333"}}},"outputs":[],"source":["\n","# RLE 디코딩 함수\n","def rle_decode(mask_rle, shape):\n","    s = mask_rle.split()\n","    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n","    starts -= 1\n","    ends = starts + lengths\n","    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n","    for lo, hi in zip(starts, ends):\n","        img[lo:hi] = 1\n","    return img.reshape(shape)\n","\n","# RLE 인코딩 함수\n","def rle_encode(mask):\n","    pixels = mask.flatten()\n","    pixels = np.concatenate([[0], pixels, [0]])\n","    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n","    runs[1::2] -= runs[::2]\n","    return ' '.join(str(x) for x in runs)"]},{"cell_type":"markdown","metadata":{"id":"DVVsT126Lsvq"},"source":["## Custom dataset"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"e4NSUOIOL7RA","executionInfo":{"status":"ok","timestamp":1690481552707,"user_tz":-540,"elapsed":34,"user":{"displayName":"박지원","userId":"06387002305792707333"}}},"outputs":[],"source":["class SatelliteDataset(Dataset):\n","    def __init__(self, csv_file, transform=None, infer=False):\n","        self.data = pd.read_csv(csv_file)\n","        self.transform = transform\n","        self.infer = infer\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.data.iloc[idx, 1]\n","        image = cv2.imread(img_path)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","        if self.infer:\n","            if self.transform:\n","                image = self.transform(image=image)['image']\n","            return image\n","\n","        mask_rle = self.data.iloc[idx, 2]\n","        mask = rle_decode(mask_rle, (image.shape[0], image.shape[1]))\n","\n","        if self.transform:\n","            augmented = self.transform(image=image, mask=mask)\n","            image = augmented['image']\n","            mask = augmented['mask']\n","\n","        return image, mask"]},{"cell_type":"markdown","metadata":{"id":"ADVSIlHVMAfA"},"source":["## Data Loader"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"dLAKZBXaMDf5","executionInfo":{"status":"ok","timestamp":1690481870995,"user_tz":-540,"elapsed":336,"user":{"displayName":"박지원","userId":"06387002305792707333"}}},"outputs":[],"source":["transform = A.Compose(\n","    [\n","        #A.CenterCrop(224, 224, p=0.7),\n","        A.RandomCrop(224, 224, p=1),\n","\n","        #A.HorizontalFlip(p = 0.5),\n","        #A.HorizontalFlip(p = 0.5),\n","\n","        #A.IAAAdditiveGaussianNoise(p=0.2),\n","        #A.IAAPerspective(p=0.5),\n","\n","        #A.OneOf([\n","            #A.CLAHE(p=1),\n","            #A.RandomBrightness(p = 1),\n","            #A.RandomGamma(p = 1)\n","        #], p = 0.5),\n","\n","        #A.OneOf([\n","            #A.IAASharpen(p = 1),\n","            #A.Blur(blur_limit=3, p=1),\n","            #A.GaussianBlur(p = 1),\n","            #A.MotionBlur(blur_limit=3, p=1),\n","            #A.GaussNoise(p = 1)\n","        #], p = 0.5),\n","\n","        #A.OneOf([\n","            #A.RandomContrast(p=1),\n","            #A.HueSaturationValue(p=1),\n","        #], p = 0.5),\n","\n","        A.Resize(224, 224),\n","\n","        A.Normalize(),\n","        ToTensorV2()\n","    ]\n",")\n","\n","transform_test = A.Compose(\n","    [\n","        A.Resize(224, 224),\n","\n","        A.Normalize(),\n","        ToTensorV2()\n","    ]\n",")"]},{"cell_type":"markdown","metadata":{"id":"cNN36DN3MFxZ"},"source":["##Define Model"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6752,"status":"ok","timestamp":1690481559427,"user":{"displayName":"박지원","userId":"06387002305792707333"},"user_tz":-540},"id":"QUfeyfpuZ4fj","outputId":"9c4495fd-e94c-4f3f-b20e-7ed30e174ec0"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b7-dcc49843.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b7-dcc49843.pth\n","100%|██████████| 254M/254M [00:03<00:00, 73.7MB/s]\n"]}],"source":["import ssl\n","ssl._create_default_https_context = ssl._create_unverified_context\n","\n","ENCODER = 'efficientnet-b7'\n","ENCODER_WEIGHTS = 'imagenet'\n","ACTIVATION = 'sigmoid'\n","DEVICE = 'cuda'\n","\n","model = smp.Unet(\n","    encoder_name = ENCODER,\n","    encoder_weights = ENCODER_WEIGHTS,\n","    in_channels = 3,\n","    classes = 1,\n","    activation = ACTIVATION,\n",")"]},{"cell_type":"markdown","metadata":{"id":"my-bpy4bHoJh"},"source":["##CutMix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-k9-nqMRHsRZ"},"outputs":[],"source":["def cutmix(batch, alpha=1.0, p=0):\n","    '''\n","    alpha 값을 1.0으로 설정하여 beta 분포가 uniform 분포가 되도록 함으로써,\n","    두 이미지를 랜덤하게 combine하는 Cutmix\n","    '''\n","\n","    data, targets = batch\n","\n","    # cutmix 확률 설정\n","    if np.random.random() > p:\n","        return data, (targets, torch.zeros_like(targets), 1.0)\n","\n","    indices = torch.randperm(data.size(0))\n","    shuffled_data = data[indices]\n","    shuffled_targets = targets[indices]\n","    lam = np.random.beta(alpha, alpha)\n","\n","    image_h, image_w = data.shape[2:]\n","    cx = np.random.uniform(0, image_w)\n","    cy = np.random.uniform(0, image_h)\n","    w = image_w * np.sqrt(1 - lam)\n","    h = image_h * np.sqrt(1 - lam)\n","    x0 = int(np.round(max(cx - w / 2, 0)))\n","    x1 = int(np.round(min(cx + w / 2, image_w)))\n","    y0 = int(np.round(max(cy - h / 2, 0)))\n","    y1 = int(np.round(min(cy + h / 2, image_h)))\n","\n","    data[:, :, y0:y1, x0:x1] = shuffled_data[:, :, y0:y1, x0:x1]\n","    targets = (targets, shuffled_targets, lam)\n","\n","    return data, targets\n","\n","\n","class CutMixCollator:\n","    def __init__(self, alpha, p):\n","        self.alpha = alpha\n","        self.p = p\n","\n","    def __call__(self, batch):\n","        batch = torch.utils.data.dataloader.default_collate(batch)\n","        batch = cutmix(batch, self.alpha, self.p)\n","        return batch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i22StoWaUX3o"},"outputs":[],"source":["import segmentation_models_pytorch.utils\n","\n","dice = smp.utils.losses.DiceLoss().to(device)\n","bce = smp.utils.losses.BCELoss().to(device)\n","criterion = dice + bce\n","\n","class CutMixCriterion:\n","    def __init__(self):\n","        self.criterion = criterion\n","\n","    def __call__(self, preds, targets):\n","        targets1, targets2, lam = targets\n","        targets1 = targets1.unsqueeze(1)\n","        targets2 = targets2.unsqueeze(1)\n","        return lam * self.criterion(\n","            preds, targets1) + (1 - lam) * self.criterion(preds, targets2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"01bbJcV8H5uw"},"outputs":[],"source":["collator = CutMixCollator(alpha=1.0, p=0.5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ICSMBwa0JYKh"},"outputs":[],"source":["train_ds = SatelliteDataset(csv_file='train.csv', transform=transform)\n","train_dl = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=2, collate_fn = collator)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0LI-EV4LQtWk"},"outputs":[],"source":["train_dl2 = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=2)"]},{"cell_type":"markdown","metadata":{"id":"KYL91DCyMNjs"},"source":["##Model Train"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4749774,"status":"ok","timestamp":1690107132649,"user":{"displayName":"박지원","userId":"06387002305792707333"},"user_tz":-540},"id":"89yFx12SMRBN","outputId":"5000dc1c-68f8-4d73-d2ec-d9b052d8aca8"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 447/447 [06:35<00:00,  1.13it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, Loss: 0.47684793257606645\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 447/447 [06:35<00:00,  1.13it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, Loss: 0.46629898013417886\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 447/447 [06:36<00:00,  1.13it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3, Loss: 0.4696188758416997\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 447/447 [06:34<00:00,  1.13it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4, Loss: 0.46042601827540386\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 447/447 [06:35<00:00,  1.13it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5, Loss: 0.46407618942010054\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 447/447 [06:36<00:00,  1.13it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 6, Loss: 0.45874292686814966\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 447/447 [06:36<00:00,  1.13it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 7, Loss: 0.4844204377741355\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 447/447 [06:36<00:00,  1.13it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 8, Loss: 0.4412586076780987\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 447/447 [06:36<00:00,  1.13it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 9, Loss: 0.4649586028667371\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 447/447 [06:35<00:00,  1.13it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10, Loss: 0.4499515781566601\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 447/447 [06:34<00:00,  1.13it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11, Loss: 0.46342988278908487\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 447/447 [06:35<00:00,  1.13it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 12, Loss: 0.45735307176174467\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["\n","\n","# loss function과 optimizer 정의\n","#dice = smp.utils.losses.DiceLoss()\n","#bce = smp.utils.losses.BCELoss()\n","#criterion = dice + bce\n","\n","train_criterion = CutMixCriterion()\n","\n","#optimizer = torch.optim.Adam([dict(params=model.parameters(), lr=0.0001),])\n","optimizer = torch.optim.AdamW([dict(params=model.parameters(), lr=0.0001, weight_decay = 0.001),])\n","#optimizer = AdamP(params=model.parameters(), lr=0.001, betas=(0.9, 0.999), weight_decay=1e-4)\n","\n","# training loop\n","for epoch in range(12):  # 10 에폭 동안 학습합니다.\n","    model.train()\n","    model.to('cuda')\n","    epoch_loss = 0\n","    for images, masks in tqdm(train_dl):\n","        images = images.float().to(device)\n","        targets1, targets2, lam = masks\n","        masks = (targets1.float().to(device), targets2.float().to(device), lam)\n","\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = train_criterion(outputs, masks)\n","        loss.backward()\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","\n","    print(f'Epoch {epoch+1}, Loss: {epoch_loss/len(train_dl)}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V4MqezeNvXCi"},"outputs":[],"source":["torch.save(model.state_dict(), '../drive/MyDrive/ef7+dicebce+adamW+rand224_1+cutmix.pth')"]},{"cell_type":"markdown","metadata":{"id":"jutLc5KNbENg"},"source":["##Inference"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12400,"status":"ok","timestamp":1690481855412,"user":{"displayName":"박지원","userId":"06387002305792707333"},"user_tz":-540},"id":"wqx810IOrlkC","outputId":"3b00ed01-258c-4690-b29e-e6afec34fa1d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":12}],"source":["model.load_state_dict(torch.load('../drive/MyDrive/ef7+dicebce+adamW+rand224_1+cutmix.pth'))"]},{"cell_type":"code","source":["def apply_densecrf(image, mask):\n","    # Convert mask to 1D label array\n","    mask = mask.cpu().numpy()\n","    mask = np.argmax(mask, axis=1)\n","\n","    # Convert image and mask to 1D arrays\n","    image = image.cpu().numpy()\n","    image = np.transpose(image.squeeze(), (1, 2, 0))  # [C, H, W] -> [H, W, C]\n","    mask = mask.squeeze()\n","\n","    # Create a dense CRF object\n","    d = dcrf.DenseCRF2D(image.shape[1], image.shape[0], num_classes)\n","    U = -np.log(mask)\n","\n","    # Set unary potentials (neg log probability)\n","    d.setUnaryEnergy(U)\n","\n","    # Add pairwise potentials (image-dependent features)\n","    d.addPairwiseBilateral(sxy=(80, 80), srgb=(13, 13, 13), rgbim=np.copy(image), compat=10)\n","\n","    # Run inference\n","    Q = d.inference(5)\n","\n","    # Convert the results to 1-hot encoding\n","    one_hot = np.zeros((num_classes, image.shape[0], image.shape[1]), dtype=np.uint8)\n","    for i in range(num_classes):\n","        one_hot[i, :, :] = (Q == i).reshape((image.shape[0], image.shape[1]))\n","\n","    # Convert back to the original shape [C, H, W]\n","    one_hot = torch.from_numpy(np.expand_dims(one_hot, axis=0)).float()\n","    return one_hot"],"metadata":{"id":"WWdUxHJshhhg","executionInfo":{"status":"ok","timestamp":1690482235064,"user_tz":-540,"elapsed":366,"user":{"displayName":"박지원","userId":"06387002305792707333"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3714,"status":"ok","timestamp":1690482107740,"user":{"displayName":"박지원","userId":"06387002305792707333"},"user_tz":-540},"id":"fmDTbjkCOAbo","outputId":"b5b41d92-3ced-4bc7-e445-ba041fb12f61"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: ttach in /usr/local/lib/python3.10/dist-packages (0.0.3)\n"]}],"source":["pip install ttach"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"BrBKyHU6OO0H","executionInfo":{"status":"ok","timestamp":1690481861008,"user_tz":-540,"elapsed":16,"user":{"displayName":"박지원","userId":"06387002305792707333"}}},"outputs":[],"source":["import ttach as tta\n","transforms = tta.Compose(\n","    [\n","        tta.HorizontalFlip(),\n","        #tta.Rotate90(angles=[0, 90]),\n","        #tta.Scale(scales=[1,2,4])\n","    ]\n",")"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"O8EPwknCbHU_","executionInfo":{"status":"ok","timestamp":1690481876487,"user_tz":-540,"elapsed":384,"user":{"displayName":"박지원","userId":"06387002305792707333"}}},"outputs":[],"source":["test_dataset = SatelliteDataset(csv_file='test.csv', transform=transform_test, infer=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=2)"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":432},"executionInfo":{"elapsed":1231,"status":"error","timestamp":1690482287132,"user":{"displayName":"박지원","userId":"06387002305792707333"},"user_tz":-540},"id":"Tf-YBsLYbJax","outputId":"33b8566f-2d1e-4e9d-97a1-5c41c502d048"},"outputs":[{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/3790 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([16, 3, 224, 224])\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/3790 [00:00<?, ?it/s]\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-37-51a1b0f7366b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtta_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0moutput_with_crf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_densecrf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_with_crf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-34-2200a1a9feb4>\u001b[0m in \u001b[0;36mapply_densecrf\u001b[0;34m(image, mask)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Convert image and mask to 1D arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [C, H, W] -> [H, W, C]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mtranspose\u001b[0;34m(*args, **kwargs)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mtranspose\u001b[0;34m(a, axes)\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \"\"\"\n\u001b[0;32m--> 660\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'transpose'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: axes don't match array"]}],"source":["with torch.no_grad():\n","    model.eval()\n","\n","    tta_model = tta.SegmentationTTAWrapper(model, transforms)\n","    tta_model.to(device)\n","    result = []\n","    for images in tqdm(test_dataloader):\n","        images = images.float().to(device)\n","\n","        outputs = tta_model(images)\n","        print(images.size())\n","        output_with_crf = apply_densecrf(images, outputs)\n","        masks = output_with_crf.cpu().numpy()\n","        masks = np.squeeze(masks, axis=1)\n","        masks = (masks > 0.35).astype(np.uint8) # Threshold = 0.35\n","\n","        for i in range(len(images)):\n","            mask_rle = rle_encode(masks[i])\n","            if mask_rle == '': # 예측된 건물 픽셀이 아예 없는 경우 -1\n","                result.append(-1)\n","            else:\n","                result.append(mask_rle)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":892775,"status":"ok","timestamp":1690108098960,"user":{"displayName":"박지원","userId":"06387002305792707333"},"user_tz":-540},"id":"eb3r04Feoiyv","outputId":"9abac47e-1dcc-44f7-8029-9e054200e0ac"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 3790/3790 [14:52<00:00,  4.25it/s]\n"]}],"source":["with torch.no_grad():\n","    model.eval()\n","    model.to(device)\n","    result = []\n","    for images in tqdm(test_dataloader):\n","        images = images.float().to(device)\n","\n","        outputs = model(images)\n","        masks = outputs.cpu().numpy()\n","        masks = np.squeeze(masks, axis=1)\n","        masks = (masks > 0.35).astype(np.uint8) # Threshold = 0.35\n","\n","        for i in range(len(images)):\n","            mask_rle = rle_encode(masks[i])\n","            if mask_rle == '': # 예측된 건물 픽셀이 아예 없는 경우 -1\n","                result.append(-1)\n","            else:\n","                result.append(mask_rle)"]},{"cell_type":"markdown","metadata":{"id":"AhPl-_NZbLl_"},"source":["##Submission"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"npVyzOOobPAu","colab":{"base_uri":"https://localhost:8080/","height":190},"executionInfo":{"status":"error","timestamp":1690481861506,"user_tz":-540,"elapsed":510,"user":{"displayName":"박지원","userId":"06387002305792707333"}},"outputId":"2a594383-e920-4fe0-8b5d-2b8023b52490"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-0d2e0ebea5df>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msubmit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sample_submission.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msubmit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask_rle'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"]}],"source":["submit = pd.read_csv('sample_submission.csv')\n","submit['mask_rle'] = result"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"WwNWJcpLbPzv","executionInfo":{"status":"ok","timestamp":1690481862206,"user_tz":-540,"elapsed":8,"user":{"displayName":"박지원","userId":"06387002305792707333"}}},"outputs":[],"source":["submit.to_csv('../drive/MyDrive/densecrf_try1.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1YyLL3-7uJr1sKZzqYE33gN_j7ODnjoZq"},"executionInfo":{"elapsed":26186,"status":"ok","timestamp":1690108317892,"user":{"displayName":"박지원","userId":"06387002305792707333"},"user_tz":-540},"id":"TLL8b1FGZX5X","outputId":"ec3370f2-9bf4-4640-934c-7ae826a484b7"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["test_data = pd.read_csv('test.csv')\n","submit1 = pd.read_csv('../drive/MyDrive/ef7+dicebce+adamW+rand224_1+cutmix_tta.csv')\n","submit2 = pd.read_csv('../drive/MyDrive/densecrf_try1.csv')\n","\n","import matplotlib.pyplot as plt\n","\n","for i in range(10050,10100):\n","    test_image_path = test_data['img_path'][i]\n","    test_image = cv2.imread(test_image_path)\n","    test_mask1 = rle_decode(submit1['mask_rle'][i], (224,224))\n","    test_mask2 = rle_decode(submit2['mask_rle'][i], (224,224))\n","\n","    plt.figure(figsize=(10,10))\n","    plt.subplot(131)\n","    plt.imshow(test_image)\n","    plt.axis(\"off\")\n","    plt.subplot(132)\n","    plt.imshow(test_mask1)\n","    plt.axis(\"off\")\n","    plt.subplot(133)\n","    plt.imshow(test_mask2)\n","    plt.axis(\"off\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k2aea7FxIiyk"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"}},"nbformat":4,"nbformat_minor":0}