{"cells":[{"cell_type":"markdown","metadata":{"id":"z-yeM27xLt8K"},"source":["## Import"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","#데이터있는 주소\n","%cd /content/drive/MyDrive/Ai/\n","!unzip -qq \"/content/drive/MyDrive/Ai/open.zip\""],"metadata":{"id":"tWCg-8Wkacj3","colab":{"base_uri":"https://localhost:8080/"},"outputId":"98469ac1-e972-4830-c41c-2c09a9b1bf94"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Ai\n","replace sample_submission.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n","replace test.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n","replace train.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"]}]},{"cell_type":"code","source":["%pip install segmentation-models-pytorch\n","%pip install ttach"],"metadata":{"id":"Eimwz4EufcB3","colab":{"base_uri":"https://localhost:8080/"},"outputId":"96acf393-2246-4fb8-93dc-10911c980f9a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting segmentation-models-pytorch\n","  Downloading segmentation_models_pytorch-0.3.3-py3-none-any.whl (106 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (0.15.2+cu118)\n","Collecting pretrainedmodels==0.7.4 (from segmentation-models-pytorch)\n","  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting efficientnet-pytorch==0.7.1 (from segmentation-models-pytorch)\n","  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting timm==0.9.2 (from segmentation-models-pytorch)\n","  Downloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (4.65.0)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (8.4.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.0.1+cu118)\n","Collecting munch (from pretrainedmodels==0.7.4->segmentation-models-pytorch)\n","  Downloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation-models-pytorch) (6.0.1)\n","Collecting huggingface-hub (from timm==0.9.2->segmentation-models-pytorch)\n","  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors (from timm==0.9.2->segmentation-models-pytorch)\n","  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.22.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (2.27.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (4.7.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (16.0.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (2023.6.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (23.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2023.5.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (3.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.3.0)\n","Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n","  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16427 sha256=7e81569e682a1814e63cea06ad34a2da0f4b116faf84da5d05ee8d7115fd88e6\n","  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n","  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60945 sha256=a9c7310c246fde83e8d3eb8f0eab5d3a4006beef7fd4683b160880fe6807fd32\n","  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\n","Successfully built efficientnet-pytorch pretrainedmodels\n","Installing collected packages: safetensors, munch, huggingface-hub, timm, pretrainedmodels, efficientnet-pytorch, segmentation-models-pytorch\n","Successfully installed efficientnet-pytorch-0.7.1 huggingface-hub-0.16.4 munch-4.0.0 pretrainedmodels-0.7.4 safetensors-0.3.1 segmentation-models-pytorch-0.3.3 timm-0.9.2\n","Collecting ttach\n","  Downloading ttach-0.0.3-py3-none-any.whl (9.8 kB)\n","Installing collected packages: ttach\n","Successfully installed ttach-0.0.3\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VolGYa0kJKqY"},"outputs":[],"source":["import os\n","import cv2\n","import random\n","import pandas as pd\n","import numpy as np\n","import ttach as tta\n","import math\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","from torch.optim.lr_scheduler import _LRScheduler\n","\n","from sklearn.model_selection import KFold, train_test_split\n","\n","from tqdm import tqdm\n","\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","from typing import List, Union\n","from joblib import Parallel, delayed\n","\n","import segmentation_models_pytorch as smp\n","import argparse\n","import ssl"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YwpW6h9DY2aN","colab":{"base_uri":"https://localhost:8080/"},"outputId":"eeac6322-4969-4da9-9fdb-182212ab6f9e"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"]},{"cell_type":"markdown","metadata":{"id":"7hqKAYTPY2aO"},"source":["## Fix Randomseed"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SDaH1E5KY2aO"},"outputs":[],"source":["def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = True\n","\n","seed_everything(41) # Seed 고정"]},{"cell_type":"markdown","metadata":{"id":"3KnPjwNmLwfR"},"source":["## Utils"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"88cEQaQyLhJZ"},"outputs":[],"source":["# RLE 디코딩 함수\n","def rle_decode(mask_rle, shape):\n","    s = mask_rle.split()\n","    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n","    starts -= 1\n","    ends = starts + lengths\n","    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n","    for lo, hi in zip(starts, ends):\n","        img[lo:hi] = 1\n","    return img.reshape(shape)\n","\n","# RLE 인코딩 함수\n","def rle_encode(mask):\n","    pixels = mask.flatten()\n","    pixels = np.concatenate([[0], pixels, [0]])\n","    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n","    runs[1::2] -= runs[::2]\n","    return ' '.join(str(x) for x in runs)"]},{"cell_type":"markdown","metadata":{"id":"3cbHZynDY2aP"},"source":["## Data Load"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"obqtbd-4Y2aP"},"outputs":[],"source":["train_data = pd.read_csv('/content/drive/MyDrive/Ai/train.csv')"]},{"cell_type":"markdown","metadata":{"id":"DVVsT126Lsvq"},"source":["## Custom Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e4NSUOIOL7RA"},"outputs":[],"source":["class SatelliteDataset(Dataset):\n","    def __init__(self, csv_file, transform=None, infer=False):\n","        self.data = pd.read_csv(csv_file)\n","        self.transform = transform\n","        self.infer = infer\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.data.iloc[idx, 1]\n","        image = cv2.imread(img_path)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","        if self.infer:\n","            if self.transform:\n","                image = self.transform(image=image)['image']\n","            return image\n","\n","        mask_rle = self.data.iloc[idx, 2]\n","        mask = rle_decode(mask_rle, (image.shape[0], image.shape[1]))\n","\n","        if self.transform:\n","            augmented = self.transform(image=image, mask=mask)\n","            image = augmented['image']\n","            mask = augmented['mask']\n","\n","        return image, mask"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gYWCDqFGY2aQ"},"outputs":[],"source":["train_transform = A.Compose(\n","    [\n","        A.RandomCrop(224, 224, p=1),\n","        A.Normalize(),\n","        ToTensorV2()\n","    ]\n",")\n","\n","val_transform = A.Compose(\n","    [\n","        A.CenterCrop(224, 224, p=1),\n","        A.Normalize(),\n","        ToTensorV2()\n","    ]\n",")\n","\n","test_transform = A.Compose(\n","    [\n","        A.Resize(224, 224),\n","        A.Normalize(),\n","        ToTensorV2()\n","    ]\n",")"]},{"cell_type":"markdown","metadata":{"id":"ADVSIlHVMAfA"},"source":["## Data Loader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QUfeyfpuZ4fj","colab":{"base_uri":"https://localhost:8080/"},"outputId":"99eb0361-454e-4d81-8e4c-1e69bc165777"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_efficientnet_b7_ap-ddb28fec.pth\" to /root/.cache/torch/hub/checkpoints/tf_efficientnet_b7_ap-ddb28fec.pth\n","100%|██████████| 254M/254M [00:02<00:00, 124MB/s]\n"]}],"source":["import ssl\n","ssl._create_default_https_context = ssl._create_unverified_context\n","\n","ENCODER = 'timm-efficientnet-b7'\n","ENCODER_WEIGHTS = 'advprop'\n","ACTIVATION = 'sigmoid'\n","DEVICE = 'cuda'\n","\n","from segmentation_models_pytorch.encoders import get_preprocessing_fn\n","preprocess_input = get_preprocessing_fn('timm-efficientnet-b7', pretrained='advprop')\n","\n","model = smp.UnetPlusPlus(\n","    encoder_name = ENCODER,\n","    encoder_depth=4,\n","    encoder_weights = ENCODER_WEIGHTS,\n","    in_channels = 3,\n","    decoder_channels=(256, 128, 64, 32),\n","    classes = 1,\n","    activation = ACTIVATION,\n",")"]},{"cell_type":"markdown","metadata":{"id":"KYL91DCyMNjs"},"source":["##Loss Function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ReJmhu_tdyfL"},"outputs":[],"source":["import re\n","\n","class BaseObject(nn.Module):\n","    def __init__(self, name=None):\n","        super().__init__()\n","        self._name = name\n","\n","    @property\n","    def __name__(self):\n","        if self._name is None:\n","            name = self.__class__.__name__\n","            s1 = re.sub(\"(.)([A-Z][a-z]+)\", r\"\\1_\\2\", name)\n","            return re.sub(\"([a-z0-9])([A-Z])\", r\"\\1_\\2\", s1).lower()\n","        else:\n","            return self._name\n","\n","\n","class Metric(BaseObject):\n","    pass\n","\n","\n","class Loss(BaseObject):\n","    def __add__(self, other):\n","        if isinstance(other, Loss):\n","            return SumOfLosses(self, other)\n","        else:\n","            raise ValueError(\"Loss should be inherited from `Loss` class\")\n","\n","    def __radd__(self, other):\n","        return self.__add__(other)\n","\n","    def __mul__(self, value):\n","        if isinstance(value, (int, float)):\n","            return MultipliedLoss(self, value)\n","        else:\n","            raise ValueError(\"Loss should be inherited from `BaseLoss` class\")\n","\n","    def __rmul__(self, other):\n","        return self.__mul__(other)\n","\n","\n","class SumOfLosses(Loss):\n","    def __init__(self, l1, l2):\n","        name = \"{} + {}\".format(l1.__name__, l2.__name__)\n","        super().__init__(name=name)\n","        self.l1 = l1\n","        self.l2 = l2\n","\n","    def __call__(self, *inputs):\n","        return self.l1.forward(*inputs) + self.l2.forward(*inputs)\n","\n","\n","class MultipliedLoss(Loss):\n","    def __init__(self, loss, multiplier):\n","\n","        # resolve name\n","        if len(loss.__name__.split(\"+\")) > 1:\n","            name = \"{} * ({})\".format(multiplier, loss.__name__)\n","        else:\n","            name = \"{} * {}\".format(multiplier, loss.__name__)\n","        super().__init__(name=name)\n","        self.loss = loss\n","        self.multiplier = multiplier\n","\n","    def __call__(self, *inputs):\n","        return self.multiplier * self.loss.forward(*inputs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"THbmhXXMdzGz"},"outputs":[],"source":["def _take_channels(*xs, ignore_channels=None):\n","    if ignore_channels is None:\n","        return xs\n","    else:\n","        channels = [channel for channel in range(xs[0].shape[1]) if channel not in ignore_channels]\n","        xs = [torch.index_select(x, dim=1, index=torch.tensor(channels).to(x.device)) for x in xs]\n","        return xs\n","\n","\n","def _threshold(x, threshold=None):\n","    if threshold is not None:\n","        return (x > threshold).type(x.dtype)\n","    else:\n","        return x\n","\n","\n","def iou(pr, gt, eps=1e-7, threshold=None, ignore_channels=None):\n","    \"\"\"Calculate Intersection over Union between ground truth and prediction\n","    Args:\n","        pr (torch.Tensor): predicted tensor\n","        gt (torch.Tensor):  ground truth tensor\n","        eps (float): epsilon to avoid zero division\n","        threshold: threshold for outputs binarization\n","    Returns:\n","        float: IoU (Jaccard) score\n","    \"\"\"\n","\n","    pr = _threshold(pr, threshold=threshold)\n","    pr, gt = _take_channels(pr, gt, ignore_channels=ignore_channels)\n","\n","    intersection = torch.sum(gt * pr)\n","    union = torch.sum(gt) + torch.sum(pr) - intersection + eps\n","    return (intersection + eps) / union\n","\n","\n","jaccard = iou\n","\n","\n","def f_score(pr, gt, beta=1, eps=1e-7, threshold=None, ignore_channels=None):\n","    \"\"\"Calculate F-score between ground truth and prediction\n","    Args:\n","        pr (torch.Tensor): predicted tensor\n","        gt (torch.Tensor):  ground truth tensor\n","        beta (float): positive constant\n","        eps (float): epsilon to avoid zero division\n","        threshold: threshold for outputs binarization\n","    Returns:\n","        float: F score\n","    \"\"\"\n","\n","    pr = _threshold(pr, threshold=threshold)\n","    pr, gt = _take_channels(pr, gt, ignore_channels=ignore_channels)\n","\n","    tp = torch.sum(gt * pr)\n","    fp = torch.sum(pr) - tp\n","    fn = torch.sum(gt) - tp\n","\n","    score = ((1 + beta**2) * tp + eps) / ((1 + beta**2) * tp + beta**2 * fn + fp + eps)\n","\n","    return score\n","\n","\n","def accuracy(pr, gt, threshold=0.5, ignore_channels=None):\n","    \"\"\"Calculate accuracy score between ground truth and prediction\n","    Args:\n","        pr (torch.Tensor): predicted tensor\n","        gt (torch.Tensor):  ground truth tensor\n","        eps (float): epsilon to avoid zero division\n","        threshold: threshold for outputs binarization\n","    Returns:\n","        float: precision score\n","    \"\"\"\n","    pr = _threshold(pr, threshold=threshold)\n","    pr, gt = _take_channels(pr, gt, ignore_channels=ignore_channels)\n","\n","    tp = torch.sum(gt == pr, dtype=pr.dtype)\n","    score = tp / gt.view(-1).shape[0]\n","    return score\n","\n","\n","def precision(pr, gt, eps=1e-7, threshold=None, ignore_channels=None):\n","    \"\"\"Calculate precision score between ground truth and prediction\n","    Args:\n","        pr (torch.Tensor): predicted tensor\n","        gt (torch.Tensor):  ground truth tensor\n","        eps (float): epsilon to avoid zero division\n","        threshold: threshold for outputs binarization\n","    Returns:\n","        float: precision score\n","    \"\"\"\n","\n","    pr = _threshold(pr, threshold=threshold)\n","    pr, gt = _take_channels(pr, gt, ignore_channels=ignore_channels)\n","\n","    tp = torch.sum(gt * pr)\n","    fp = torch.sum(pr) - tp\n","\n","    score = (tp + eps) / (tp + fp + eps)\n","\n","    return score\n","\n","\n","def recall(pr, gt, eps=1e-7, threshold=None, ignore_channels=None):\n","    \"\"\"Calculate Recall between ground truth and prediction\n","    Args:\n","        pr (torch.Tensor): A list of predicted elements\n","        gt (torch.Tensor):  A list of elements that are to be predicted\n","        eps (float): epsilon to avoid zero division\n","        threshold: threshold for outputs binarization\n","    Returns:\n","        float: recall score\n","    \"\"\"\n","\n","    pr = _threshold(pr, threshold=threshold)\n","    pr, gt = _take_channels(pr, gt, ignore_channels=ignore_channels)\n","\n","    tp = torch.sum(gt * pr)\n","    fn = torch.sum(gt) - tp\n","\n","    score = (tp + eps) / (tp + fn + eps)\n","\n","    return score"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zW7d7wE3d-8z"},"outputs":[],"source":["class DiceLoss(Loss):\n","    def __init__(self, eps=1.0, beta=1.0, ignore_channels=None, **kwargs):\n","        super().__init__(**kwargs)\n","        self.eps = eps\n","        self.beta = beta\n","        self.ignore_channels = ignore_channels\n","\n","    def forward(self, y_pr, y_gt):\n","        return 1 - f_score(\n","            y_pr,\n","            y_gt,\n","            beta=self.beta,\n","            eps=self.eps,\n","            threshold=None,\n","            ignore_channels=self.ignore_channels,\n","        )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rTmWIw7weC_K"},"outputs":[],"source":["class FocalLoss(Loss):\n","    def __init__(self, alpha=1, gamma=2, class_weights=None, logits=False, reduction='mean'):\n","        super().__init__()\n","        assert reduction in ['mean', None]\n","        self.alpha = alpha\n","        self.gamma = gamma\n","        self.logits = logits\n","        self.reduction = reduction\n","        self.class_weights = class_weights if class_weights is not None else 1.\n","\n","    def forward(self, y_pr, y_gt):\n","        bce_loss = nn.functional.binary_cross_entropy(y_pr, y_gt)\n","\n","        pt = torch.exp(- bce_loss)\n","        focal_loss = self.alpha * (1 - pt) ** self.gamma * bce_loss\n","        focal_loss = focal_loss * torch.tensor(self.class_weights).to(focal_loss.device)\n","\n","        if self.reduction == 'mean':\n","            focal_loss = focal_loss.mean()\n","\n","        return focal_loss"]},{"cell_type":"markdown","metadata":{"id":"QJNQsYl1eJ0B"},"source":["## CutMix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M9m_ixTyY2aR"},"outputs":[],"source":["def cutmix(batch, alpha=1.0, p=0):\n","    '''\n","    alpha 값을 1.0으로 설정하여 beta 분포가 uniform 분포가 되도록 함으로써,\n","    두 이미지를 랜덤하게 combine하는 Cutmix\n","    '''\n","\n","    data, targets = batch\n","\n","    # cutmix 확률 설정\n","    if np.random.random() > p:\n","        return data, (targets, torch.zeros_like(targets), 1.0)\n","\n","    indices = torch.randperm(data.size(0))\n","    shuffled_data = data[indices]\n","    shuffled_targets = targets[indices]\n","    lam = np.random.beta(alpha, alpha)\n","\n","    image_h, image_w = data.shape[2:]\n","    cx = np.random.uniform(0, image_w)\n","    cy = np.random.uniform(0, image_h)\n","    w = image_w * np.sqrt(1 - lam)\n","    h = image_h * np.sqrt(1 - lam)\n","    x0 = int(np.round(max(cx - w / 2, 0)))\n","    x1 = int(np.round(min(cx + w / 2, image_w)))\n","    y0 = int(np.round(max(cy - h / 2, 0)))\n","    y1 = int(np.round(min(cy + h / 2, image_h)))\n","\n","    data[:, :, y0:y1, x0:x1] = shuffled_data[:, :, y0:y1, x0:x1]\n","    targets = (targets, shuffled_targets, lam)\n","\n","    return data, targets\n","\n","\n","class CutMixCollator:\n","    def __init__(self, alpha, p):\n","        self.alpha = alpha\n","        self.p = p\n","\n","    def __call__(self, batch):\n","        batch = torch.utils.data.dataloader.default_collate(batch)\n","        batch = cutmix(batch, self.alpha, self.p)\n","        return batch\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EeS-UmJnY2aS"},"outputs":[],"source":["dice = DiceLoss()\n","focal = FocalLoss()\n","base_criterion = dice + focal\n","\n","class CutMixCriterion:\n","    def __init__(self):\n","        self.criterion = base_criterion\n","\n","    def __call__(self, preds, targets):\n","        targets1, targets2, lam = targets\n","        targets1 = targets1.unsqueeze(1)\n","        targets2 = targets2.unsqueeze(1)\n","        return lam * self.criterion(\n","            preds, targets1) + (1 - lam) * self.criterion(preds, targets2)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JsG_U9p9Y2aS"},"outputs":[],"source":["collator = CutMixCollator(alpha=1.0, p=0.5)"]},{"cell_type":"markdown","metadata":{"id":"A9qFbdlzY2aS"},"source":["## Learning Rate Scheduler"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"agwafZpNY2aS"},"outputs":[],"source":["class CosineAnnealingWarmUpRestarts(_LRScheduler):\n","    def __init__(self, optimizer, T_0, T_mult=1, eta_max=0.1, T_up=0, gamma=1., last_epoch=-1):\n","        if T_0 <= 0 or not isinstance(T_0, int):\n","            raise ValueError(\"Expected positive integer T_0, but got {}\".format(T_0))\n","        if T_mult < 1 or not isinstance(T_mult, int):\n","            raise ValueError(\"Expected integer T_mult >= 1, but got {}\".format(T_mult))\n","        if T_up < 0 or not isinstance(T_up, int):\n","            raise ValueError(\"Expected positive integer T_up, but got {}\".format(T_up))\n","        self.T_0 = T_0\n","        self.T_mult = T_mult\n","        self.base_eta_max = eta_max\n","        self.eta_max = eta_max\n","        self.T_up = T_up\n","        self.T_i = T_0\n","        self.gamma = gamma\n","        self.cycle = 0\n","        self.T_cur = last_epoch\n","        super(CosineAnnealingWarmUpRestarts, self).__init__(optimizer, last_epoch)\n","\n","    def get_lr(self):\n","        if self.T_cur == -1:\n","            return self.base_lrs\n","        elif self.T_cur < self.T_up:\n","            return [(self.eta_max - base_lr)*self.T_cur / self.T_up + base_lr for base_lr in self.base_lrs]\n","        else:\n","            return [base_lr + (self.eta_max - base_lr) * (1 + math.cos(math.pi * (self.T_cur-self.T_up) / (self.T_i - self.T_up))) / 2\n","                    for base_lr in self.base_lrs]\n","\n","    def step(self, epoch=None):\n","        if epoch is None:\n","            epoch = self.last_epoch + 1\n","            self.T_cur = self.T_cur + 1\n","            if self.T_cur >= self.T_i:\n","                self.cycle += 1\n","                self.T_cur = self.T_cur - self.T_i\n","                self.T_i = (self.T_i - self.T_up) * self.T_mult + self.T_up\n","        else:\n","            if epoch >= self.T_0:\n","                if self.T_mult == 1:\n","                    self.T_cur = epoch % self.T_0\n","                    self.cycle = epoch // self.T_0\n","                else:\n","                    n = int(math.log((epoch / self.T_0 * (self.T_mult - 1) + 1), self.T_mult))\n","                    self.cycle = n\n","                    self.T_cur = epoch - self.T_0 * (self.T_mult ** n - 1) / (self.T_mult - 1)\n","                    self.T_i = self.T_0 * self.T_mult ** (n)\n","            else:\n","                self.T_i = self.T_0\n","                self.T_cur = epoch\n","\n","        self.eta_max = self.base_eta_max * (self.gamma**self.cycle)\n","        self.last_epoch = math.floor(epoch)\n","        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n","            param_group['lr'] = lr"]},{"cell_type":"markdown","metadata":{"id":"J3OdPjJqY2aS"},"source":["## Model Train"]},{"cell_type":"code","source":["valid_idx = np.arange(0,1428)\n","train_idx1= np.arange(1428,2856)\n","train_idx2= np.arange(2856,7140)\n","train_idx = np.concatenate((train_idx1,train_idx2 ))\n","\n","print(train_idx, valid_idx)"],"metadata":{"id":"v4l7l2gPatQZ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f664378c-6197-4594-ddbb-c99cdd5997ec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[1428 1429 1430 ... 7137 7138 7139] [   0    1    2 ... 1425 1426 1427]\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C3QYqjWQ0znT"},"outputs":[],"source":["def train_1epoch(model, train_loader, lossfun, optimizer, device):\n","    model.train()\n","    model.to('cuda')\n","    train_loss = []\n","\n","    for images, masks in tqdm(train_loader):\n","        images = images.float().to(device)\n","        targets1, targets2, lam = masks # cutmix하기 위해 label split\n","        masks = (targets1.float().to(device), targets2.float().to(device), lam)\n","\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = lossfun(outputs, masks)\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss.append(loss.item())\n","\n","    tr_loss = np.mean(train_loss)\n","    return tr_loss\n","\n","def validate_1epoch(model, val_loader, lossfun, device):\n","    model.eval()\n","    model.to(device)\n","\n","    val_loss = []\n","\n","    with torch.no_grad():\n","        for images, masks in tqdm(val_loader):\n","            images = images.float().to(device)\n","            masks = masks.float().to(device)\n","\n","            outputs = model(images)\n","            loss = lossfun(outputs, masks.unsqueeze(1))\n","\n","            val_loss.append(loss.item())\n","\n","    total_loss = np.mean(val_loss)\n","    return total_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1IH8w4o-33UF"},"outputs":[],"source":["# Test Time Augmentation\n","tta_transforms = tta.Compose(\n","    [\n","        tta.HorizontalFlip(),\n","        tta.Rotate90(angles=[0, 90, 180]),\n","        #tta.Scale(scales=[1,2,4])\n","    ]\n",")\n","\n","def predict(model, loader, device):\n","\n","    result =[]\n","    with torch.no_grad():\n","        model.eval()\n","\n","        tta_model = tta.SegmentationTTAWrapper(model, tta_transforms)\n","        tta_model.to(device)\n","        model.to(device)\n","\n","        for images in tqdm(loader):\n","            images = images.float().to(device)\n","\n","            outputs = tta_model(images)\n","            outputs = outputs.cpu().numpy()\n","            outputs = (100 * outputs).astype(np.uint8)\n","            masks = np.squeeze(outputs, axis=1)\n","\n","            masks = masks > 35\n","\n","            for i in range(len(images)):\n","                mask_rle = rle_encode(masks[i])\n","                if mask_rle == '':\n","                    result.append(-1)\n","                else:\n","                    result.append(mask_rle)\n","\n","    return result"]},{"cell_type":"code","source":["test_ds = SatelliteDataset(csv_file='/content/drive/MyDrive/Ai/test.csv', transform=test_transform, infer=True)\n","test_dl = DataLoader(test_ds, batch_size=16, shuffle=False, num_workers=2)\n","\n","train_ds = SatelliteDataset(csv_file='/content/drive/MyDrive/Ai/train.csv', transform=train_transform)\n","valid_ds = SatelliteDataset(csv_file='/content/drive/MyDrive/Ai/train.csv', transform=val_transform)\n","\n","def getDataloader(train_idx, valid_idx, collator):\n","\n","    train_subsampler = torch.utils.data.SubsetRandomSampler(train_idx)\n","    valid_subsampler = torch.utils.data.SubsetRandomSampler(valid_idx)\n","\n","    train_dl = DataLoader(train_ds,\n","                          batch_size=16,\n","                          shuffle=False,\n","                          num_workers=2,\n","                          collate_fn = collator,\n","                          sampler = train_subsampler\n","                          )\n","\n","    val_dl = DataLoader(valid_ds,\n","                        batch_size=16,\n","                        shuffle=False,\n","                        num_workers=2,\n","                        sampler = valid_subsampler\n","                        )\n","\n","\n","    return train_dl, val_dl"],"metadata":{"id":"91qj6fLtguOZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_kfold(device):\n","\n","    train_criterion = CutMixCriterion()\n","    val_criterion = dice\n","\n","    patience = 10  # 10 epoch동안 성능 향상 없을 시, early stopping\n","\n","    train_loader, val_loader = getDataloader(train_idx, valid_idx, collator=collator)\n","\n","    optimizer = torch.optim.Adam([dict(params=model.parameters(), lr=0.00001),])\n","    scheduler = CosineAnnealingWarmUpRestarts(optimizer, T_0=10, T_mult=1,\n","                                          eta_max=0.001,  T_up=3, gamma=0.7)\n","\n","    best_loss = 1\n","    best_model = None\n","    counter = 0\n","\n","    for epoch in range(20):\n","\n","        tr_loss = train_1epoch(\n","            model, train_loader, train_criterion, optimizer, device\n","        )\n","\n","        val_loss = validate_1epoch(\n","            model, val_loader, val_criterion, device\n","        )\n","\n","        print(f'Train Loss : [{tr_loss:.5f}] Val Loss : [{val_loss:.5f}]]')\n","\n","\n","        if scheduler is not None:\n","            scheduler.step()\n","\n","        if best_loss > val_loss:\n","            best_model = model\n","            best_loss = val_loss\n","            counter=0\n","            # 갱신 시마다  best model 저장 -> fold별 마지막 weight이 fold별 best weight\n","            torch.save(model.state_dict(), f\"./uppvalloss_{val_loss:.5f}.pth\")\n","        else:\n","            counter+=1\n","\n","        if counter > patience:\n","            print(\"Early Stopping...\")\n","            break\n","\n","        print(f'Best Val Loss : [{best_loss:.5f}]]')\n","\n","    result = predict(best_model, test_dl, device)\n","\n","    return result"],"metadata":{"id":"3vKkmV8WgxQp"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XUl5X1Or4wgp","outputId":"542bf961-fdc3-42a8-828b-87587d20aecc"},"outputs":[{"output_type":"stream","name":"stderr","text":["  5%|▌         | 19/357 [00:16<04:35,  1.23it/s]"]}],"source":["result=[]\n","result=train_kfold('cuda')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wqx810IOrlkC","scrolled":true},"outputs":[],"source":["model.load_state_dict(torch.load('./upp.pth'))"]},{"cell_type":"markdown","metadata":{"id":"AhPl-_NZbLl_"},"source":["## Submission"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"npVyzOOobPAu"},"outputs":[],"source":["submit = pd.read_csv('sample_submission.csv')\n","submit['mask_rle'] = result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WwNWJcpLbPzv"},"outputs":[],"source":["submit.to_csv('/content/drive/MyDrive/Ai/submit.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TLL8b1FGZX5X"},"outputs":[],"source":["test_data = pd.read_csv('/content/drive/MyDrive/Ai/test.csv')\n","submit1 = pd.read_csv('/content/drive/MyDrive/Ai/submit.csv')\n","submit2 = pd.read_csv('/content/drive/MyDrive/Ai/test.csv')\n","\n","import matplotlib.pyplot as plt\n","for i in range(25000, 25050):\n","    test_image_path = test_data['img_path'][i]\n","    test_image = cv2.imread(test_image_path)\n","    test_mask1 = rle_decode(submit1['mask_rle'][i], (224,224))\n","    test_mask2 = rle_decode(submit2['mask_rle'][i], (224,224))\n","\n","    plt.figure(figsize=(10,10))\n","    plt.subplot(131)\n","    plt.imshow(test_image)\n","    plt.axis(\"off\")\n","    plt.subplot(132)\n","    plt.imshow(test_mask1)\n","    plt.axis(\"off\")\n","    plt.subplot(133)\n","    plt.imshow(test_mask2)\n","    plt.axis(\"off\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fdJu_69k7H9g"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"TFGPU","language":"python","name":"tfgpu"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"}},"nbformat":4,"nbformat_minor":0}